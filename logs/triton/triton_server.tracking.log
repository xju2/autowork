Running workflow/scripts/start_triton_server_for_validation.sh Mon 14 Jul 2025 08:34:09 PM PDT @ login21
-----------------------------------
Mon 14 Jul 2025 08:34:09 PM PDT login21
Input File: /pscratch/sd/x/xju/code/autowork/projects/triton/triton_server.config.tracking.json
Output File: /pscratch/sd/x/xju/code/autowork/results/triton/triton_server.tracking.ready.txt
Start Triton Server for validation
SOURCE_DIR: /pscratch/sd/x/xju/ITk/ForFinalPaper
OUTPUT: /pscratch/sd/x/xju/code/autowork/results/triton/triton_server.tracking.ready.txt
REPO_URL: git@github.com:xju2/tracking-as-a-service.git
SOURCE_DIR: /pscratch/sd/x/xju/ITk/ForFinalPaper
JOB Name: triton_job
srun: job 40753289 queued and waiting for resources
Polling for job 40753289 (triton_job) to start...
Current state: PENDING. Waiting...
Current state: PENDING. Waiting...
Current state: PENDING. Waiting...
Current state: PENDING. Waiting...
Current state: PENDING. Waiting...
Current state: PENDING. Waiting...
Current state: PENDING. Waiting...
Current state: PENDING. Waiting...
Current state: PENDING. Waiting...
Current state: PENDING. Waiting...
Current state: PENDING. Waiting...
Current state: PENDING. Waiting...
Current state: PENDING. Waiting...
srun: job 40753289 has been allocated resources
Job 40753289 is RUNNING.
[slurm] starting nid008377

=============================
== Triton Inference Server ==
=============================

NVIDIA Release 24.05 (build 94071063)
Triton Server Version 2.46.0

Copyright (c) 2018-2023, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

I0715 03:34:52.292116 1 pinned_memory_manager.cc:275] "Pinned memory pool is created at '0x7ff37e000000' with size 268435456"
I0715 03:34:52.298574 1 cuda_memory_manager.cc:107] "CUDA memory pool is created on device 0 with size 67108864"
E0715 03:34:52.308534 1 server.cc:243] "CudaDriverHelper has not been initialized."
I0715 03:34:52.339513 1 model_lifecycle.cc:472] "loading: GNN4Pixel:3"
I0715 03:34:52.339629 1 model_lifecycle.cc:472] "loading: MetricLearning:2"
DONE 2025-07-14T20:34:53
I0715 03:35:03.145037 1 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: GNN4Pixel_0_0 (GPU device 0)"
I0715 03:35:03.150942 1 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: MetricLearning_0_0 (GPU device 0)"
MetricLearningInferenceConfig(model_path=PosixPath('/models/MetricLearning/2'), device='cuda', auto_cast=False, compling=False, debug=False, save_debug_data=False, r_max=0.12, k_max=1000, filter_cut=0.05, filter_batches=10, cc_cut=0.01, walk_min=0.1, walk_max=0.6, embedding_node_features=['r', 'phi', 'z', 'cluster_x_1', 'cluster_y_1', 'cluster_z_1', 'cluster_x_2', 'cluster_y_2', 'cluster_z_2', 'count_1', 'charge_count_1', 'loc_eta_1', 'loc_phi_1', 'localDir0_1', 'localDir1_1', 'localDir2_1', 'lengthDir0_1', 'lengthDir1_1', 'lengthDir2_1', 'glob_eta_1', 'glob_phi_1', 'eta_angle_1', 'phi_angle_1', 'count_2', 'charge_count_2', 'loc_eta_2', 'loc_phi_2', 'localDir0_2', 'localDir1_2', 'localDir2_2', 'lengthDir0_2', 'lengthDir1_2', 'lengthDir2_2', 'glob_eta_2', 'glob_phi_2', 'eta_angle_2', 'phi_angle_2'], embedding_node_scale=[1000.0, 3.14, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1.0, 1.0, 3.14, 3.14, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.14, 3.14, 3.14, 3.14, 1.0, 1.0, 3.14, 3.14, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.14, 3.14, 3.14, 3.14], filter_node_features=['r', 'phi', 'z', 'cluster_x_1', 'cluster_y_1', 'cluster_z_1', 'cluster_x_2', 'cluster_y_2', 'cluster_z_2', 'count_1', 'charge_count_1', 'loc_eta_1', 'loc_phi_1', 'localDir0_1', 'localDir1_1', 'localDir2_1', 'lengthDir0_1', 'lengthDir1_1', 'lengthDir2_1', 'glob_eta_1', 'glob_phi_1', 'eta_angle_1', 'phi_angle_1', 'count_2', 'charge_count_2', 'loc_eta_2', 'loc_phi_2', 'localDir0_2', 'localDir1_2', 'localDir2_2', 'lengthDir0_2', 'lengthDir1_2', 'lengthDir2_2', 'glob_eta_2', 'glob_phi_2', 'eta_angle_2', 'phi_angle_2'], filter_node_scale=[1000.0, 3.14, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1.0, 1.0, 3.14, 3.14, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.14, 3.14, 3.14, 3.14, 1.0, 1.0, 3.14, 3.14, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.14, 3.14, 3.14, 3.14], gnn_node_features=['r', 'phi', 'z', 'eta', 'cluster_r_1', 'cluster_phi_1', 'cluster_z_1', 'cluster_eta_1', 'cluster_r_2', 'cluster_phi_2', 'cluster_z_2', 'cluster_eta_2'], gnn_node_scale=[1000.0, 3.14159265359, 1000.0, 1.0, 1000.0, 3.14159265359, 1000.0, 1.0, 1000.0, 3.14159265359, 1000.0, 1.0])
I0715 03:35:07.255050 1 model_lifecycle.cc:838] "successfully loaded 'GNN4Pixel'"
I0715 03:35:07.277442 1 model_lifecycle.cc:838] "successfully loaded 'MetricLearning'"
I0715 03:35:07.277503 1 server.cc:606]
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0715 03:35:07.277543 1 server.cc:633]
+---------+-------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend | Path                                                  | Config                                                                                                                                                        |
+---------+-------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| python  | /opt/tritonserver/backends/python/libtriton_python.so | {"cmdline":{"auto-complete-config":"true","backend-directory":"/opt/tritonserver/backends","min-compute-capability":"6.000000","default-max-batch-size":"4"}} |
+---------+-------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0715 03:35:07.277584 1 server.cc:676]
+----------------+---------+--------+
| Model          | Version | Status |
+----------------+---------+--------+
| GNN4Pixel      | 3       | READY  |
| MetricLearning | 2       | READY  |
+----------------+---------+--------+

I0715 03:35:07.310534 1 metrics.cc:877] "Collecting metrics for GPU 0: NVIDIA A100-SXM4-80GB"
I0715 03:35:07.313613 1 metrics.cc:770] "Collecting CPU metrics"
I0715 03:35:07.313716 1 tritonserver.cc:2557]
+----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                           |
+----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                                          |
| server_version                   | 2.46.0                                                                                                                                                                                                          |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data parameters statistics trace logging |
| model_repository_path[0]         | /models                                                                                                                                                                                                         |
| model_control_mode               | MODE_NONE                                                                                                                                                                                                       |
| strict_model_config              | 0                                                                                                                                                                                                               |
| model_config_name                |                                                                                                                                                                                                                 |
| rate_limit                       | OFF                                                                                                                                                                                                             |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                                       |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                                        |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                             |
| strict_readiness                 | 1                                                                                                                                                                                                               |
| exit_timeout                     | 30                                                                                                                                                                                                              |
| cache_enabled                    | 0                                                                                                                                                                                                               |
+----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0715 03:35:07.318688 1 grpc_server.cc:2463] "Started GRPCInferenceService at 0.0.0.0:8001"
I0715 03:35:07.318874 1 http_server.cc:4692] "Started HTTPService at 0.0.0.0:8000"
I0715 03:35:07.360020 1 http_server.cc:362] "Started Metrics Service at 0.0.0.0:8002"
slurmstepd: error: *** STEP 40753289.0 ON nid008377 CANCELLED AT 2025-07-15T07:35:13 DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
srun: error: nid008377: task 0: Terminated
srun: Terminating StepId=40753289.0
